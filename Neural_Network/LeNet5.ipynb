{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LeNet-5 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过阅读论文 Gradient-Based Learning Applied to Document Recognition，可以得知 LeNet-5 网络结构如图：\n",
    "<img src=\"../Image/LeNet5.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不包括输入层的话，LeNet-5 由7层网络层组成，每层都包含可训练参数（权重）。输入层是一个 32$\\times$32的图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1 卷积层：\n",
    "\n",
    "- 输入：$32\\times32\\times1$\n",
    "\n",
    "- 滤波器个数：6\n",
    "\n",
    "- 滤波器大小：$5\\times5\\times1$\n",
    "\n",
    "- 输出：$28\\times28\\times6$\n",
    "\n",
    "- 参数个数：$6\\times(5\\times5+1) = 156$      # (6个特征图，每个特征图含一个滤波器 $5\\times5$ 个参数和一个偏置参数)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S2 采样层（池化层）：\n",
    "\n",
    "- 采样方式：$2\\times2$ 区域的4个值相加，乘以一个可训练参数，再加上一个偏置参数，结果通过 Sigmoid 非线性化。\n",
    "\n",
    "- 输入：$28\\times28\\times6$\n",
    "\n",
    "- 滤波器个数；6\n",
    "\n",
    "- 滤波器大小：$2\\times2$\n",
    "\n",
    "- 输出：$14\\times14\\times6$\n",
    "\n",
    "- 参数个数：$6\\times(1 + 1) = 12$     #（采样的权重 + 一个偏置参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C3 卷积层：\n",
    "\n",
    "- 输入：$14\\times14\\times6$\n",
    "\n",
    "- 滤波器个数：16\n",
    "\n",
    "- 滤波器大小：$5\\times5\\times6$\n",
    "\n",
    "- 输出：$10\\times10\\times16$\n",
    "\n",
    "- 连接方式：C3跟S2并不是全连接的，具体连接方式是： C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入，对应如下：\n",
    "\n",
    "<img src=\"../Image/LeNet5_1.png\" width=100%>\n",
    "\n",
    "- 参数个数：\n",
    "$6*（3*5*5+1）+6*（4*5*5+1）+3*（4*5*5+1）+1*（6*5*5+1）=1516$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S4 下采样层（池化层）：\n",
    "\n",
    "- 输入：$10\\times10\\times16$\n",
    "\n",
    "- 滤波器大小：$2\\times2$\n",
    "\n",
    "- 滤波器个数：16\n",
    "\n",
    "- 输出：$5\\times5\\times16$\n",
    "\n",
    "- 参数个数：$2\\times16$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C5 卷积层：\n",
    "\n",
    "- 输入：$5\\times5\\times16$\n",
    "\n",
    "- 滤波器大小：$5\\times5\\times16$\n",
    "\n",
    "- 滤波器个数：120\n",
    "\n",
    "- 输出：$1\\times1\\times120$\n",
    "\n",
    "- 参数个数：$5\\times5\\times16\\times120 + 120 = 48120$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F6 全连接层：\n",
    "\n",
    "- 输入：120\n",
    "\n",
    "- 输出：84\n",
    "\n",
    "- 参数个数：$120\\times(84 + 1) = 10164$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F7 全连接层：\n",
    "\n",
    "- 输入：84\n",
    "\n",
    "- 输出：10\n",
    "\n",
    "- 参数个数：$84\\times(10 + 1) = 850$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LeNet-5 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2431\n",
      "Epoch [1/5], Step [200/600], Loss: 0.2401\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2225\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1189\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1123\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1100\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1179\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1053\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1705\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0558\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0475\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0939\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0605\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0388\n",
      "Epoch [3/5], Step [300/600], Loss: 0.1090\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0404\n",
      "Epoch [3/5], Step [500/600], Loss: 0.1106\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0181\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0061\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0173\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0364\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0124\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0343\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0549\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0610\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0495\n",
      "Epoch [5/5], Step [300/600], Loss: 0.1158\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0088\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0269\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0126\n",
      "Test Avg. Loss: 0.00045265411608852446, Accuracy: 98.57%\n",
      "Saved model successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Device configuaration\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "input_size = 784     # 28*28 = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"../data\",\n",
    "                                         train=True,\n",
    "                                         transform=transforms.Compose([\n",
    "                                             transforms.Resize((32, 32)),\n",
    "                                             transforms.ToTensor()]),\n",
    "                                         download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../data',\n",
    "                                        train=False,\n",
    "                                        transform=transforms.Compose([\n",
    "                                             transforms.Resize((32, 32)),\n",
    "                                             transforms.ToTensor()]))\n",
    "\n",
    "# Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    Input - 1x32x32\n",
    "    C1 - 6@28x28 (5x5 kernel)\n",
    "    tanh\n",
    "    S2 - 6@14x14 (2x2 kernel, stride 2) Subsampling\n",
    "    C3 - 16@10x10\n",
    "    tanh\n",
    "    S4 - 16@5x5 (2x2 kernel, stride 2) Subsampling\n",
    "    C5 - 120@1x1 (5x5 kernel)\n",
    "    F6 - 84\n",
    "    tanh\n",
    "    F7 - 10 (Output)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),                   # C1\n",
    "            nn.ReLU(),                              # ReLU\n",
    "            nn.MaxPool2d(2, stride=2),      # S2\n",
    "            nn.Conv2d(6, 16, 5),                # C3\n",
    "            nn.ReLU(),                            # ReLU\n",
    "            nn.MaxPool2d(2, stride=2),    # S4\n",
    "            nn.Conv2d(16, 120, 5),           # C5\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(120, 84),                # F6\n",
    "            nn.ReLU(),                           # ReLU\n",
    "            nn.Linear(84, 10),                 # F7\n",
    "            nn.LogSoftmax(dim=-1))       # LogSoftmax\n",
    "        \n",
    "    def forward(self, img):\n",
    "        output = self.convnet(img)\n",
    "        output = output.view(img.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "# Create an LeNet5 instance\n",
    "net = LeNet5()\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "def train(num_epoch):\n",
    "    \"\"\"\n",
    "    It is a functino to train the LeNet5 model\n",
    "    @param: num_epoch: the number of epochs\n",
    "    \"\"\"\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epoch):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = net(images)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "                \n",
    "def test():\n",
    "    '''\n",
    "    It is a function to test the model.\n",
    "    '''\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        output = net(images)\n",
    "        avg_loss += criterion(output, labels)\n",
    "        # _, pred = torch.max(output.data, 1)\n",
    "        pred = torch.argmax(output.data, dim=1)\n",
    "        total_correct += (pred == labels).sum().item()\n",
    "    \n",
    "    avg_loss = avg_loss / len(test_dataset)\n",
    "    print(\"Test Avg. Loss: {}, Accuracy: {}%\".format(avg_loss, 100*total_correct/len(test_dataset)))\n",
    "\n",
    "def main():\n",
    "    # Train\n",
    "    train(num_epochs)\n",
    "    # Test\n",
    "    test()\n",
    "    # Save the model checkpoint\n",
    "    torch.save(net.state_dict(), \"LeNet5.ckpt\")\n",
    "    print(\"Saved model successfully!\\n\")\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2MNLrRRb6-i",
    "colab_type": "text"
   },
   "source": [
    "# Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TytF3getbyAK",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122.0
    },
    "outputId": "0810daf4-b962-466c-c574-81656163a2c2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575455161377E12,
     "user_tz": -480.0,
     "elapsed": 19858.0,
     "user": {
      "displayName": "Yantong Laii",
      "photoUrl": "",
      "userId": "11292323517047847832"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1jokZN8lcBfZ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "76b6969a-1a4f-4313-92ac-355142f8a717",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575455164712E12,
     "user_tz": -480.0,
     "elapsed": 1721.0,
     "user": {
      "displayName": "Yantong Laii",
      "photoUrl": "",
      "userId": "11292323517047847832"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Pytorch Learning/Python3\n"
     ]
    }
   ],
   "source": [
    "% cd '/content/drive/My Drive/Pytorch Learning/Python3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6PGoPi-zcI_8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68.0
    },
    "outputId": "2184acca-a2c2-4189-905e-5e7319c60834",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.57545517433E12,
     "user_tz": -480.0,
     "elapsed": 7159.0,
     "user": {
      "displayName": "Yantong Laii",
      "photoUrl": "",
      "userId": "11292323517047847832"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10.py\t     LeNet5.ckpt      __pycache__\n",
      "LeNet5_CIFAR10.ckpt  LeNet5_MNIST.py  RNN_sentiemnt_custom_dataset_GloVe.ipynb\n",
      "LeNet5_CIFAR10.py    LeNet5.py\t      RNN_sentiemnt_custom_dataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqMef69Bb-sp",
    "colab_type": "text"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "250qesxbbarE",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "outputId": "dfb7ca69-a285-40c0-a77e-2b9ce59975ba",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575456274171E12,
     "user_tz": -480.0,
     "elapsed": 264443.0,
     "user": {
      "displayName": "Yantong Laii",
      "photoUrl": "",
      "userId": "11292323517047847832"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train_data = 25000\n",
      "Number of test_data = 25000\n",
      "vars(train_data[0]) = {'labels': 'pos', 'text': ['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', ',', 'such', 'as', '\"', 'Teachers', '\"', '.', 'My', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'Bromwell', 'High', \"'s\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"', 'Teachers', '\"', '.', 'The', 'scramble', 'to', 'survive', 'financially', ',', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', \"'\", 'pomp', ',', 'the', 'pettiness', 'of', 'the', 'whole', 'situation', ',', 'all', 'remind', 'me', 'of', 'the', 'schools', 'I', 'knew', 'and', 'their', 'students', '.', 'When', 'I', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', ',', 'I', 'immediately', 'recalled', '.........', 'at', '..........', 'High', '.', 'A', 'classic', 'line', ':', 'INSPECTOR', ':', 'I', \"'m\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers', '.', 'STUDENT', ':', 'Welcome', 'to', 'Bromwell', 'High', '.', 'I', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'Bromwell', 'High', 'is', 'far', 'fetched', '.', 'What', 'a', 'pity', 'that', 'it', 'is', \"n't\", '!']}\n",
      "\n",
      "Number of train_data = 17500\n",
      "Number of valid_data = 7500\n",
      "Number of test_data = 25000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:31, 2.20MB/s]                           \n",
      "100%|█████████▉| 398937/400000 [00:15<00:00, 26621.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars(train_data[0]) =  {'labels': 'neg', 'text': ['This', 'movie', 'has', 'got', 'to', 'be', 'one', 'of', 'the', 'worst', 'I', 'have', 'ever', 'seen', 'make', 'it', 'to', 'DVD', '!', '!', '!', 'The', 'story', 'line', 'might', 'have', 'clicked', 'if', 'the', 'film', 'had', 'more', 'funding', 'and', 'writers', 'that', 'would', 'have', 'cut', 'the', 'nonsense', 'and', 'sickly', 'scenes', 'that', 'I', 'highly', 'caution', 'parents', 'on', '....', 'But', 'the', 'story', 'line', 'is', 'like', 'a', 'loose', 'cannon', '.', 'If', 'there', 'was', 'such', 'a', 'thing', 'as', 'a', 'drive', 'thru', 'movie', 'maker', '-', 'this', 'one', 'would', 'have', 'sprung', 'from', 'that', '.', 'It', 'reminded', 'me', 'a', 'lot', 'of', 'the', 'quickie', 'films', 'that', 'were', 'put', 'out', 'in', 'the', '1960', \"'s\", ',', 'poor', 'script', 'writing', 'and', 'filming', '.', '<', 'br', '/><br', '/>The', 'only', 'sensible', 'characters', 'in', 'the', 'whole', 'movie', 'was', 'the', 'bartender', 'and', 'beaver', '.', 'The', 'rest', 'of', 'the', 'film', ',', 'could', 'have', 'easily', 'been', 'made', 'by', 'middle', 'school', 'children', '.', 'I', 'give', 'this', 'film', 'a', 'rating', 'of', '1', 'as', 'it', 'is', 'truly', 'awful', 'and', 'left', 'my', 'entire', 'family', 'with', 'a', 'sense', 'of', 'being', 'cheated', '.', 'My', 'advice', '-', \"Don't\", 'Watch', 'It', '!', '!', '!']}\n",
      "INPUT_DIM = 101960\n",
      "OUTPUT_DIM = 2\n",
      "The model has 12507170 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|█████████▉| 398937/400000 [00:29<00:00, 26621.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/69], Loss: 0.6829\n",
      "Epoch [1/10], Step [20/69], Loss: 0.6739\n",
      "Epoch [1/10], Step [30/69], Loss: 0.6387\n",
      "Epoch [1/10], Step [40/69], Loss: 0.6598\n",
      "Epoch [1/10], Step [50/69], Loss: 0.6832\n",
      "Epoch [1/10], Step [60/69], Loss: 0.6102\n",
      "total_loss = [0.6938649415969849, 0.6905660629272461, 0.6941353678703308, 0.689378559589386, 0.6933417916297913, 0.6792043447494507, 0.695667028427124, 0.6693956851959229, 0.697924792766571, 0.6829426288604736, 0.6896958947181702, 0.6787241697311401, 0.6732372641563416, 0.672018826007843, 0.6558898091316223, 0.6705135107040405, 0.6711212992668152, 0.6775741577148438, 0.680449903011322, 0.6739197373390198, 0.6648499369621277, 0.6462147235870361, 0.6752798557281494, 0.6568111181259155, 0.7018011212348938, 0.6360228657722473, 0.6259579658508301, 0.6817304491996765, 0.6352450847625732, 0.6387157440185547, 0.650404155254364, 0.6776708960533142, 0.672187864780426, 0.6507013440132141, 0.6595985293388367, 0.65294349193573, 0.6530744433403015, 0.6256859302520752, 0.6347015500068665, 0.659791111946106, 0.6341230273246765, 0.6269457936286926, 0.6572512984275818, 0.6064305901527405, 0.5949555039405823, 0.5990726351737976, 0.5906095504760742, 0.5793341398239136, 0.6801860928535461, 0.6831587553024292, 0.5721783638000488, 0.599845826625824, 0.6233473420143127, 0.6198166608810425, 0.6136395931243896, 0.5934659838676453, 0.6293408274650574, 0.587681770324707, 0.6134370565414429, 0.6102170944213867, 0.5891809463500977, 0.5530156493186951, 0.6519761681556702, 0.6422851085662842, 0.5649452805519104, 0.516900897026062, 0.6151261329650879, 0.6063077449798584, 0.6238813996315002]\n",
      "\n",
      "Epoch [2/10], Step [10/69], Loss: 0.5536\n",
      "Epoch [2/10], Step [20/69], Loss: 0.5003\n",
      "Epoch [2/10], Step [30/69], Loss: 0.5649\n",
      "Epoch [2/10], Step [40/69], Loss: 0.5034\n",
      "Epoch [2/10], Step [50/69], Loss: 0.5887\n",
      "Epoch [2/10], Step [60/69], Loss: 0.4914\n",
      "total_loss = [0.5259368419647217, 0.5675383806228638, 0.5543758273124695, 0.5486032366752625, 0.5260511636734009, 0.522990345954895, 0.5465093851089478, 0.5653131008148193, 0.5532277822494507, 0.5536301732063293, 0.5489703416824341, 0.536633312702179, 0.4865449368953705, 0.5537781715393066, 0.45634713768959045, 0.5432792901992798, 0.5147678256034851, 0.497780978679657, 0.5500965714454651, 0.500331699848175, 0.5282057523727417, 0.5734822154045105, 0.5055739879608154, 0.49397891759872437, 0.5636044144630432, 0.5163360834121704, 0.5742685794830322, 0.5171675086021423, 0.4970661997795105, 0.5649328827857971, 0.508716881275177, 0.529988706111908, 0.5665290951728821, 0.5127597451210022, 0.5112419128417969, 0.5637062191963196, 0.4799767732620239, 0.5181031227111816, 0.46191471815109253, 0.5034063458442688, 0.5720158815383911, 0.4577777683734894, 0.5179823040962219, 0.5875562429428101, 0.6015796661376953, 0.6267148852348328, 0.5500105619430542, 0.5646477341651917, 0.6239113807678223, 0.5887221097946167, 0.5691906809806824, 0.5725445747375488, 0.5962542295455933, 0.5530643463134766, 0.5527910590171814, 0.5909227728843689, 0.5300562381744385, 0.546453058719635, 0.5773220062255859, 0.4914396107196808, 0.5187680721282959, 0.5119482278823853, 0.46566665172576904, 0.6228139400482178, 0.5363777875900269, 0.46274533867836, 0.5414735078811646, 0.4920974373817444, 0.5134046077728271]\n",
      "\n",
      "Epoch [3/10], Step [10/69], Loss: 0.5249\n",
      "Epoch [3/10], Step [20/69], Loss: 0.6035\n",
      "Epoch [3/10], Step [30/69], Loss: 0.4576\n",
      "Epoch [3/10], Step [40/69], Loss: 0.4809\n",
      "Epoch [3/10], Step [50/69], Loss: 0.5408\n",
      "Epoch [3/10], Step [60/69], Loss: 0.4947\n",
      "total_loss = [0.46552518010139465, 0.4562456011772156, 0.40271803736686707, 0.4355066120624542, 0.6727213263511658, 0.7784656286239624, 0.4877154529094696, 0.4597616195678711, 0.5155102610588074, 0.5249356031417847, 0.5563026070594788, 0.5243867635726929, 0.4823036789894104, 0.45048433542251587, 0.4449872076511383, 0.4679403007030487, 0.4269644618034363, 0.5321711897850037, 0.5430638194084167, 0.6035156846046448, 0.4814413785934448, 0.5382466912269592, 0.511432945728302, 0.4185052812099457, 0.4539494514465332, 0.4778158664703369, 0.4663853347301483, 0.448814332485199, 0.5123074054718018, 0.4576079547405243, 0.4329310953617096, 0.4960921108722687, 0.4425177276134491, 0.4710610806941986, 0.45929884910583496, 0.48641109466552734, 0.491137832403183, 0.44650325179100037, 0.42984551191329956, 0.4809349775314331, 0.5333065390586853, 0.41235318779945374, 0.4261220693588257, 0.460701584815979, 0.4517728090286255, 0.5514911413192749, 0.8367423415184021, 0.5392935276031494, 0.5487547516822815, 0.5407736897468567, 0.5764437317848206, 0.5060707330703735, 0.6087285280227661, 0.5437653660774231, 0.5478144288063049, 0.5210988521575928, 0.48727625608444214, 0.5126145482063293, 0.502277135848999, 0.4947483539581299, 0.5245586633682251, 0.5107715725898743, 0.4996894299983978, 0.5241600275039673, 0.4363851249217987, 0.48981866240501404, 0.5137143731117249, 0.4638650119304657, 0.5319117307662964]\n",
      "\n",
      "Epoch [4/10], Step [10/69], Loss: 0.4566\n",
      "Epoch [4/10], Step [20/69], Loss: 0.3468\n",
      "Epoch [4/10], Step [30/69], Loss: 0.4649\n",
      "Epoch [4/10], Step [40/69], Loss: 0.4294\n",
      "Epoch [4/10], Step [50/69], Loss: 0.3612\n",
      "Epoch [4/10], Step [60/69], Loss: 0.3728\n",
      "total_loss = [0.42488986253738403, 0.48073315620422363, 0.48552149534225464, 0.42016610503196716, 0.4635027348995209, 0.3986791968345642, 0.525767982006073, 0.4204352796077728, 0.4550820589065552, 0.4565516710281372, 0.43396270275115967, 0.3943478763103485, 0.4892466068267822, 0.380687415599823, 0.4731391370296478, 0.3781276345252991, 0.33070188760757446, 0.4156821668148041, 0.4693900942802429, 0.3467525541782379, 0.40783971548080444, 0.46783944964408875, 0.5634865760803223, 0.4332519471645355, 0.40818876028060913, 0.567570686340332, 0.5171301364898682, 0.38724634051322937, 0.4203946888446808, 0.46490490436553955, 0.4377139210700989, 0.37766900658607483, 0.4040234684944153, 0.3512626588344574, 0.4277447462081909, 0.3358449339866638, 0.41412630677223206, 0.4239346385002136, 0.4067678153514862, 0.4294375479221344, 0.38681912422180176, 0.35891473293304443, 0.41668349504470825, 0.3648699223995209, 0.4420525133609772, 0.33087751269340515, 0.4071916341781616, 0.4481179118156433, 0.35240235924720764, 0.3612099587917328, 0.37456217408180237, 0.3548623025417328, 0.39712661504745483, 0.39314237236976624, 0.4085921049118042, 0.379669725894928, 0.3991367518901825, 0.3553662896156311, 0.4362303912639618, 0.3728283941745758, 0.3212210536003113, 0.3670123517513275, 0.3467943072319031, 0.3425382077693939, 0.3578479588031769, 0.398069828748703, 0.4115527272224426, 0.29230400919914246, 0.43272683024406433]\n",
      "\n",
      "Epoch [5/10], Step [10/69], Loss: 0.3134\n",
      "Epoch [5/10], Step [20/69], Loss: 0.2901\n",
      "Epoch [5/10], Step [30/69], Loss: 0.4757\n",
      "Epoch [5/10], Step [40/69], Loss: 0.3719\n",
      "Epoch [5/10], Step [50/69], Loss: 0.3484\n",
      "Epoch [5/10], Step [60/69], Loss: 0.4082\n",
      "total_loss = [0.348116934299469, 0.3558216989040375, 0.36426201462745667, 0.3732272982597351, 0.33601370453834534, 0.34154775738716125, 0.3705541789531708, 0.2956865727901459, 0.35809919238090515, 0.31343743205070496, 0.30096933245658875, 0.2864219546318054, 0.4276040494441986, 0.40598344802856445, 0.3073383569717407, 0.3492268919944763, 0.4313821792602539, 0.3087349236011505, 0.3037487864494324, 0.2900809049606323, 0.38197213411331177, 0.2976882755756378, 0.316389799118042, 0.3452247977256775, 0.3749084174633026, 0.3717278242111206, 0.28303253650665283, 0.2731941342353821, 0.3251654803752899, 0.4756695032119751, 0.3785141110420227, 0.3088356554508209, 0.2886785864830017, 0.44959840178489685, 0.29779279232025146, 0.3096702992916107, 0.2712000906467438, 0.32315751910209656, 0.3125092089176178, 0.37189239263534546, 0.2892904281616211, 0.3348940908908844, 0.26833438873291016, 0.26048433780670166, 0.35642877221107483, 0.3109530806541443, 0.3216354250907898, 0.3655937612056732, 0.32848045229911804, 0.3483843207359314, 0.34982746839523315, 0.339633047580719, 0.3503330945968628, 0.35355037450790405, 0.32149413228034973, 0.31328967213630676, 0.40919291973114014, 0.31276586651802063, 0.3086702823638916, 0.40821757912635803, 0.3170144855976105, 0.2625804543495178, 0.3255380094051361, 0.32726287841796875, 0.29349836707115173, 0.31868618726730347, 0.32021549344062805, 0.31912410259246826, 0.3468545377254486]\n",
      "\n",
      "Epoch [6/10], Step [10/69], Loss: 0.2880\n",
      "Epoch [6/10], Step [20/69], Loss: 0.2315\n",
      "Epoch [6/10], Step [30/69], Loss: 0.2439\n",
      "Epoch [6/10], Step [40/69], Loss: 0.2735\n",
      "Epoch [6/10], Step [50/69], Loss: 0.2947\n",
      "Epoch [6/10], Step [60/69], Loss: 0.2939\n",
      "total_loss = [0.32125160098075867, 0.2983616590499878, 0.26862749457359314, 0.3417372405529022, 0.23698489367961884, 0.34569060802459717, 0.4227219820022583, 0.38377460837364197, 0.291233628988266, 0.2879796028137207, 0.3377856910228729, 0.3790995180606842, 0.36851340532302856, 0.29548394680023193, 0.3598664700984955, 0.23325029015541077, 0.3339424431324005, 0.24194467067718506, 0.2540229856967926, 0.23149143159389496, 0.29084694385528564, 0.2555733919143677, 0.3364918828010559, 0.3356665372848511, 0.23917482793331146, 0.2323116660118103, 0.319806307554245, 0.24512486159801483, 0.3225080072879791, 0.24390551447868347, 0.2895015776157379, 0.26104462146759033, 0.19051593542099, 0.29046258330345154, 0.27926263213157654, 0.31321561336517334, 0.2880287170410156, 0.2745562791824341, 0.2891365885734558, 0.27353379130363464, 0.23311863839626312, 0.30841007828712463, 0.2993287444114685, 0.31558656692504883, 0.2872064411640167, 0.27041831612586975, 0.24934440851211548, 0.264580637216568, 0.27839991450309753, 0.2946721017360687, 0.2507800757884979, 0.23274733126163483, 0.2543344795703888, 0.3023267090320587, 0.3146543502807617, 0.30155426263809204, 0.33275628089904785, 0.326576292514801, 0.3254588842391968, 0.2938636541366577, 0.341744601726532, 0.370640367269516, 0.3067731559276581, 0.23380345106124878, 0.2873837649822235, 0.2575945556163788, 0.30381327867507935, 0.3234744369983673, 0.3103393018245697]\n",
      "\n",
      "Epoch [7/10], Step [10/69], Loss: 0.2594\n",
      "Epoch [7/10], Step [20/69], Loss: 0.2488\n",
      "Epoch [7/10], Step [30/69], Loss: 0.2108\n",
      "Epoch [7/10], Step [40/69], Loss: 0.2160\n",
      "Epoch [7/10], Step [50/69], Loss: 0.2270\n",
      "Epoch [7/10], Step [60/69], Loss: 0.1981\n",
      "total_loss = [0.22068417072296143, 0.2147158682346344, 0.2649645507335663, 0.25823545455932617, 0.24396255612373352, 0.2631784975528717, 0.2730178236961365, 0.22684934735298157, 0.27046194672584534, 0.2594296932220459, 0.1869615763425827, 0.2516520023345947, 0.23876574635505676, 0.269460529088974, 0.28744789958000183, 0.27153486013412476, 0.18583714962005615, 0.29880520701408386, 0.25697898864746094, 0.24883931875228882, 0.20414862036705017, 0.21652963757514954, 0.22884336113929749, 0.3190610408782959, 0.28087225556373596, 0.2185577154159546, 0.2769714593887329, 0.2754223048686981, 0.20728044211864471, 0.2107550948858261, 0.19053024053573608, 0.2694112956523895, 0.21484355628490448, 0.2552095949649811, 0.2212926596403122, 0.22829605638980865, 0.2241945117712021, 0.17933297157287598, 0.1775473654270172, 0.21600116789340973, 0.2555314600467682, 0.2098626047372818, 0.22579491138458252, 0.2943412959575653, 0.24644924700260162, 0.24619612097740173, 0.2553998529911041, 0.2185288816690445, 0.20233075320720673, 0.22697483003139496, 0.2164839655160904, 0.17427778244018555, 0.26431789994239807, 0.2679685950279236, 0.22147361934185028, 0.23685309290885925, 0.2053602635860443, 0.20700344443321228, 0.20471061766147614, 0.19811445474624634, 0.19289441406726837, 0.17521043121814728, 0.31109610199928284, 0.19400206208229065, 0.22489100694656372, 0.23224058747291565, 0.22544097900390625, 0.2053845226764679, 0.25833043456077576]\n",
      "\n",
      "Epoch [8/10], Step [10/69], Loss: 0.2243\n",
      "Epoch [8/10], Step [20/69], Loss: 0.2113\n",
      "Epoch [8/10], Step [30/69], Loss: 0.1462\n",
      "Epoch [8/10], Step [40/69], Loss: 0.1510\n",
      "Epoch [8/10], Step [50/69], Loss: 0.1654\n",
      "Epoch [8/10], Step [60/69], Loss: 0.1857\n",
      "total_loss = [0.23591873049736023, 0.22912314534187317, 0.20504410564899445, 0.23497426509857178, 0.20375214517116547, 0.24380673468112946, 0.2052866816520691, 0.1499301791191101, 0.16654188930988312, 0.2243323177099228, 0.213371142745018, 0.1937532275915146, 0.14680270850658417, 0.13838323950767517, 0.1494295597076416, 0.1807539016008377, 0.17545689642429352, 0.23655402660369873, 0.21277335286140442, 0.2112591415643692, 0.21855154633522034, 0.15004731714725494, 0.2057792991399765, 0.20973211526870728, 0.2543348968029022, 0.17747610807418823, 0.1534952074289322, 0.252729207277298, 0.16432785987854004, 0.1461937576532364, 0.17157679796218872, 0.19200845062732697, 0.14401297271251678, 0.18426813185214996, 0.1324763000011444, 0.1692228615283966, 0.1706320196390152, 0.17249520123004913, 0.19607707858085632, 0.15097931027412415, 0.22447745501995087, 0.1938197910785675, 0.20635627210140228, 0.17817866802215576, 0.19765521585941315, 0.21623595058918, 0.28697073459625244, 0.21557223796844482, 0.1861487627029419, 0.16542461514472961, 0.2516207695007324, 0.2825639545917511, 0.20708486437797546, 0.1734212338924408, 0.18496891856193542, 0.2378697544336319, 0.18203943967819214, 0.19682390987873077, 0.14952486753463745, 0.18574191629886627, 0.20296870172023773, 0.18442556262016296, 0.21745364367961884, 0.16590042412281036, 0.1747829020023346, 0.1884934902191162, 0.16015061736106873, 0.16998645663261414, 0.18968039751052856]\n",
      "\n",
      "Epoch [9/10], Step [10/69], Loss: 0.1326\n",
      "Epoch [9/10], Step [20/69], Loss: 0.1112\n",
      "Epoch [9/10], Step [30/69], Loss: 0.1420\n",
      "Epoch [9/10], Step [40/69], Loss: 0.1245\n",
      "Epoch [9/10], Step [50/69], Loss: 0.0919\n",
      "Epoch [9/10], Step [60/69], Loss: 0.2244\n",
      "total_loss = [0.13552452623844147, 0.11357524245977402, 0.12356221675872803, 0.17003558576107025, 0.15508989989757538, 0.06632266193628311, 0.1262112557888031, 0.10440316051244736, 0.12129843980073929, 0.1325993835926056, 0.1769997626543045, 0.11622539162635803, 0.17097721993923187, 0.09729617834091187, 0.15816764533519745, 0.08052017539739609, 0.10748624801635742, 0.1450929492712021, 0.13862988352775574, 0.11123790591955185, 0.13120976090431213, 0.16863568127155304, 0.1912393569946289, 0.1850191354751587, 0.17359840869903564, 0.17167598009109497, 0.11920061707496643, 0.18454404175281525, 0.16778792440891266, 0.14198239147663116, 0.21305786073207855, 0.20700611174106598, 0.09826502203941345, 0.13194897770881653, 0.13370326161384583, 0.13000525534152985, 0.11901628226041794, 0.15958453714847565, 0.16234789788722992, 0.12451483309268951, 0.1881050020456314, 0.2113391011953354, 0.12062644213438034, 0.11595553904771805, 0.15322278439998627, 0.18636566400527954, 0.2031264752149582, 0.12917858362197876, 0.11640545725822449, 0.09190776199102402, 0.200858935713768, 0.2501063942909241, 0.3248947262763977, 0.11015776544809341, 0.21532145142555237, 0.17257343232631683, 0.24259710311889648, 0.16161300241947174, 0.23357728123664856, 0.22444896399974823, 0.20947952568531036, 0.2024659663438797, 0.22126244008541107, 0.28793492913246155, 0.24677282571792603, 0.1721465289592743, 0.1358993649482727, 0.18152077496051788, 0.1719534695148468]\n",
      "\n",
      "Epoch [10/10], Step [10/69], Loss: 0.1518\n",
      "Epoch [10/10], Step [20/69], Loss: 0.1193\n",
      "Epoch [10/10], Step [30/69], Loss: 0.0911\n",
      "Epoch [10/10], Step [40/69], Loss: 0.1078\n",
      "Epoch [10/10], Step [50/69], Loss: 0.1474\n",
      "Epoch [10/10], Step [60/69], Loss: 0.1464\n",
      "total_loss = [0.18024270236492157, 0.1694895327091217, 0.15189535915851593, 0.18342062830924988, 0.21533799171447754, 0.15295732021331787, 0.1322919726371765, 0.10069764405488968, 0.14313770830631256, 0.15176275372505188, 0.16549618542194366, 0.1440199911594391, 0.12498682737350464, 0.1499379426240921, 0.12794865667819977, 0.10685252398252487, 0.17300446331501007, 0.11082349717617035, 0.16499045491218567, 0.11925815790891647, 0.09904250502586365, 0.12328455597162247, 0.11755853146314621, 0.1503758430480957, 0.13070639967918396, 0.12860830128192902, 0.1470234990119934, 0.11830706894397736, 0.1639367640018463, 0.09110467880964279, 0.11999862641096115, 0.10533945262432098, 0.09124778211116791, 0.09719706326723099, 0.09825193136930466, 0.18201987445354462, 0.14761357009410858, 0.2218099981546402, 0.07585459202528, 0.10783457010984421, 0.15710030496120453, 0.2073649764060974, 0.16748648881912231, 0.25237080454826355, 0.1914944350719452, 0.12019140273332596, 0.14737676084041595, 0.18646501004695892, 0.10244134813547134, 0.14736472070217133, 0.1203819066286087, 0.16905950009822845, 0.12337717413902283, 0.13781984150409698, 0.13386960327625275, 0.12988439202308655, 0.14373905956745148, 0.16805802285671234, 0.15467797219753265, 0.14642184972763062, 0.11494320631027222, 0.11491389572620392, 0.13245107233524323, 0.10513734072446823, 0.12159799784421921, 0.16053327918052673, 0.1124386340379715, 0.09871447831392288, 0.1029970720410347]\n",
      "\n",
      "Test Avg. Loss: 0.0018619497632980347, Accuracy: 83.888%\n"
     ]
    }
   ],
   "source": [
    "# coding=utf8\n",
    "\"\"\"\n",
    "@author: Yantong Lai\n",
    "@date: 2019.12.4\n",
    "\"\"\"\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext import data, datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Dataset path\n",
    "dataset_path = \"../../data/aclImdb/\"\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "####################################\n",
    "#         Hyper-parameters         #\n",
    "####################################\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "####################################\n",
    "#          Preparing Data          #\n",
    "####################################\n",
    "# 1. data.Field()\n",
    "TEXT = data.Field(tokenize='spacy', include_lengths=True)\n",
    "LABELS = data.LabelField()\n",
    "\n",
    "# 2. data.TabularDataset\n",
    "train_data, test_data = data.TabularDataset.splits(path=dataset_path,\n",
    "                                                   train=\"train.tsv\",\n",
    "                                                   test=\"test.tsv\",\n",
    "                                                   fields=[('labels', LABELS), ('text', TEXT)],\n",
    "                                                   format=\"tsv\")\n",
    "\n",
    "# train_data, test_data = datasets.IMDB.splits(TEXT, LABELS)\n",
    "\n",
    "print(\"Number of train_data = {}\".format(len(train_data)))\n",
    "print(\"Number of test_data = {}\".format(len(test_data)))\n",
    "\n",
    "print(\"vars(train_data[0]) = {}\\n\".format(vars(train_data[0])))\n",
    "\n",
    "# 3. Split train_data to train_data, valid_data\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
    "print(\"Number of train_data = {}\".format(len(train_data)))\n",
    "print(\"Number of valid_data = {}\".format(len(valid_data)))\n",
    "print(\"Number of test_data = {}\\n\".format(len(test_data)))\n",
    "\n",
    "\n",
    "# 4. data.BucketIterator\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               device=device,\n",
    "                                                               sort_key=lambda x: len(x.text))\n",
    "# 5. Build vocab\n",
    "# TEXT.build_vocab(train_data)\n",
    "# unk_init=torch.Tensor.normal_)\n",
    "# LABELS.build_vocab(train_data)\n",
    "# print(\"vars(train_data[0]) = \", vars(train_data[0]))\n",
    "\n",
    "# 5.1 (Optional) If build vocab with pre-trained word embedding vectors\n",
    "TEXT.build_vocab(train_data, vectors=\"glove.6B.100d\")\n",
    "LABELS.build_vocab(train_data)\n",
    "print(\"vars(train_data[0]) = \", vars(train_data[0]))\n",
    "\n",
    "\n",
    "\n",
    "####################################\n",
    "#          Build the Model         #\n",
    "####################################\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        # 1. Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # 2. RNN layer\n",
    "        self.rnn = nn.LSTM(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=bidirectional,\n",
    "                           dropout=dropout)\n",
    "\n",
    "        # 3. Linear layer\n",
    "        self.fc = nn.Linear(in_features=hidden_dim * 2,\n",
    "                            out_features=output_dim)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "\n",
    "        # 1. Embedding\n",
    "        # text = [sent len, batch size]\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        # 2. Pack sequence\n",
    "        # embedded = [sent len, batch size, embed size]\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n",
    "\n",
    "        # 3. RNN\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "\n",
    "        # 4. Unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        # output = [sent len, batch size, hid dim * num_directions]\n",
    "        # output over padding tokens are zero tensors\n",
    "\n",
    "        # hidden = [num_layers * num_directions, batch size, hid dim]\n",
    "        # cell = [num_layers * num_directions, batch_size, hid dim]\n",
    "\n",
    "        # 5. Concat the final forward (hidden[-2, :, :]) and backward (hidden[-1, :, :])\n",
    "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        # hidden = [batch size, hid dim * num_directions]\n",
    "\n",
    "        # return self.fc(hidden.squeeze(0)).view(-1)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Parameters\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 2\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROUPOUT = 0.5\n",
    "# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "print(\"INPUT_DIM = {}\".format(INPUT_DIM))\n",
    "print(\"OUTPUT_DIM = {}\".format(OUTPUT_DIM))\n",
    "# print(\"TEXT.pad_token = {}\".format(TEXT.pad_token))\n",
    "# print(\"PAD_IDX = {}\".format(PAD_IDX))\n",
    "\n",
    "# Create an RNN instance\n",
    "model = RNN(vocab_size=INPUT_DIM,\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            n_layers=N_LAYERS,\n",
    "            bidirectional=BIDIRECTIONAL,\n",
    "            dropout=DROUPOUT)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"The model has {} trainable parameters\".format(count_parameters(model)))\n",
    "\n",
    "\n",
    "####################################\n",
    "#          Train the Model         #\n",
    "####################################\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "########## Train ##########\n",
    "NUM_EPOCHS = 10\n",
    "total_step = len(train_iter)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = []\n",
    "    for i, batch in enumerate(train_iter):\n",
    "\n",
    "        text, text_lengths = batch.text\n",
    "        y = batch.labels\n",
    "        # print(\"y = {}\".format(y))\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(text, text_lengths)\n",
    "        # print(\"y_pred = {}\".format(y_pred))\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, NUM_EPOCHS, i + 1, total_step, loss.item()))\n",
    "\n",
    "    print(\"total_loss = {}\\n\".format(total_loss))\n",
    "\n",
    "\n",
    "########## Test ##########\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "avg_loss = 0.0\n",
    "for i, batch in enumerate(test_iter):\n",
    "    text, text_lengths = batch.text\n",
    "\n",
    "    y = batch.labels\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(text, text_lengths)\n",
    "    loss = criterion(y_pred, y)\n",
    "    avg_loss += loss.item()\n",
    "\n",
    "    # _, pred = torch.max(output.data, 1)\n",
    "    pred = torch.argmax(y_pred.data, dim=1)\n",
    "    total_correct += (pred == y).sum().item()\n",
    "\n",
    "avg_loss = avg_loss / len(test_data)\n",
    "print(\"Test Avg. Loss: {}, Accuracy: {}%\"\n",
    "      .format(avg_loss, 100 * total_correct / len(test_data)))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RNN_sentiemnt_custom_dataset_GloVe.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
